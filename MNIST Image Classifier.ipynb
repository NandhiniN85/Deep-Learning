{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the training dataset: (60000, 784)\n",
      "size of the testing dataset: (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras import optimizers\n",
    "from keras.layers import Flatten\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "\n",
    "(train_features, train_targets), (test_features, test_targets) = mnist.load_data()\n",
    "\n",
    "train_features = train_features.reshape(60000, 784)\n",
    "print('size of the training dataset:', train_features.shape)\n",
    "test_features = test_features.reshape(10000, 784)\n",
    "print('size of the testing dataset:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalising the input data\n",
    "train_features = train_features / 255.0\n",
    "test_features = test_features / 255.0\n",
    "\n",
    "train_x = train_features\n",
    "train_y = train_targets\n",
    "\n",
    "test_x = test_features\n",
    "test_y = test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corresponding labels for the images: [5 0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "# visualizing the first 10 images in the dataset and their labels\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(train_x[i].reshape(28, 28))\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('Corresponding labels for the images: %s' % (train_y[0:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before conversion: [5 0 4 1 9]\n",
      "\n",
      "After conversion:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Before conversion:', train_y[:5])\n",
    "\n",
    "y_train = to_categorical(train_y)\n",
    "y_test = to_categorical(test_y)\n",
    "\n",
    "print('\\nAfter conversion:\\n', y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df = pd.DataFrame([], columns = [['train_score', 'test_score', 'test_F1_score']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model1: A simple neural network with sigmoid in hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50, input_shape = (784, )))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.fit(train_x, y_train, validation_data = (test_x, y_test), batch_size = 256, epochs = 30, verbose = 0)\n",
    "\n",
    "predict_y = model.predict(test_x)\n",
    "predict_value = predict_y.argmax(axis=1)\n",
    "actual_value = y_test.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df.loc['simple_sigmoid', 'train_score'] = model.evaluate(train_x, y_train, verbose=0)[1]\n",
    "accuracy_df.loc['simple_sigmoid', 'test_score'] = model.evaluate(test_x, y_test, verbose=0)[1]\n",
    "accuracy_df.loc['simple_sigmoid', 'test_F1_score'] = f1_score(actual_value, predict_value, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model2: Enhancement done to weight initialization technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(50, input_shape = (784, ), kernel_initializer='he_normal'))     # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(50, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('sigmoid'))    \n",
    "    model.add(Dense(10, kernel_initializer='he_normal'))                            # use he_normal initializer\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr = 0.001)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp_model()\n",
    "\n",
    "model.fit(train_x, y_train, validation_data = (test_x, y_test), batch_size = 256, epochs = 30, verbose = 0)\n",
    "\n",
    "predict_y = model.predict(test_x)\n",
    "predict_value = predict_y.argmax(axis=1)\n",
    "actual_value = y_test.argmax(axis=1)\n",
    "\n",
    "accuracy_df.loc['sigmoid_weight_imp', 'train_score'] = model.evaluate(train_x, y_train, verbose=0)[1]\n",
    "accuracy_df.loc['sigmoid_weight_imp', 'test_score'] = model.evaluate(test_x, y_test, verbose=0)[1]\n",
    "accuracy_df.loc['sigmoid_weight_imp', 'test_F1_score'] = f1_score(actual_value, predict_value, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple_sigmoid</th>\n",
       "      <td>0.112367</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.0231383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid_weight_imp</th>\n",
       "      <td>0.112367</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.0231383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   train_score test_score test_F1_score\n",
       "simple_sigmoid        0.112367     0.1135     0.0231383\n",
       "sigmoid_weight_imp    0.112367     0.1135     0.0231383"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model3 => using Non linear function ReLU.\n",
    "Since sigmoid and tanh suffer from vanishing gradient problem where there is no learning at higher positive and negative side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(200, input_shape = (784, ), kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(200, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(200, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(200, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr = 0.001)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp_model()\n",
    "\n",
    "model.fit(train_x, y_train, validation_data = (test_x, y_test), batch_size = 256, epochs = 30, verbose = 0)\n",
    "\n",
    "predict_y = model.predict(test_x)\n",
    "predict_value = predict_y.argmax(axis=1)\n",
    "actual_value = y_test.argmax(axis=1)\n",
    "\n",
    "accuracy_df.loc['simple_ReLU', 'train_score'] = model.evaluate(train_x, y_train, verbose=0)[1]\n",
    "accuracy_df.loc['simple_ReLU', 'test_score'] = model.evaluate(test_x, y_test, verbose=0)[1]\n",
    "accuracy_df.loc['simple_ReLU', 'test_F1_score'] = f1_score(actual_value, predict_value, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple_sigmoid</th>\n",
       "      <td>0.112367</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.0231383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid_weight_imp</th>\n",
       "      <td>0.112367</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.0231383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_ReLU</th>\n",
       "      <td>0.909467</td>\n",
       "      <td>0.9126</td>\n",
       "      <td>0.91234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   train_score test_score test_F1_score\n",
       "simple_sigmoid        0.112367     0.1135     0.0231383\n",
       "sigmoid_weight_imp    0.112367     0.1135     0.0231383\n",
       "simple_ReLU           0.909467     0.9126       0.91234"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model4 => using Non linear function ReLU with batch normalization and adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(200, input_shape = (784, ), kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(200, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu')) \n",
    "    model.add(Dense(200, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(200, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))          \n",
    "    model.add(Dense(10, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    adam = optimizers.Adam(lr = 0.001)\n",
    "    model.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mlp_model()\n",
    "\n",
    "model.fit(train_x, y_train, validation_data = (test_x, y_test), batch_size = 256, epochs = 30, verbose = 0)\n",
    "\n",
    "predict_y = model.predict(test_x)\n",
    "predict_value = predict_y.argmax(axis=1)\n",
    "actual_value = y_test.argmax(axis=1)\n",
    "\n",
    "accuracy_df.loc['ReLU_Adam_norm', 'train_score'] = model.evaluate(train_x, y_train, verbose=0)[1]\n",
    "accuracy_df.loc['ReLU_Adam_norm', 'test_score'] = model.evaluate(test_x, y_test, verbose=0)[1]\n",
    "accuracy_df.loc['ReLU_Adam_norm', 'test_F1_score'] = f1_score(actual_value, predict_value, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>test_F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple_sigmoid</th>\n",
       "      <td>0.112367</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.0231383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigmoid_weight_imp</th>\n",
       "      <td>0.112367</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.0231383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple_ReLU</th>\n",
       "      <td>0.909467</td>\n",
       "      <td>0.9126</td>\n",
       "      <td>0.91234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU_Adam_norm</th>\n",
       "      <td>0.994017</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>0.975293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   train_score test_score test_F1_score\n",
       "simple_sigmoid        0.112367     0.1135     0.0231383\n",
       "sigmoid_weight_imp    0.112367     0.1135     0.0231383\n",
       "simple_ReLU           0.909467     0.9126       0.91234\n",
       "ReLU_Adam_norm        0.994017     0.9753      0.975293"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
