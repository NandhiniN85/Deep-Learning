{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple Neural Network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvhRRObbB3ZV"
      },
      "source": [
        "Import the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jf90k-SF1j0X"
      },
      "source": [
        "from sklearn.datasets import load_iris\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Activation, Dense\r\n",
        "from keras import optimizers"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8pIr85kCAWf"
      },
      "source": [
        "We will use iris dataset for the implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNuUtYKd1pD4"
      },
      "source": [
        "iris = load_iris()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hc1_stqDCjM3",
        "outputId": "44c6898a-8fdc-4395-fbd4-dab046553d6f"
      },
      "source": [
        "iris.keys()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICYaITTT2fD0"
      },
      "source": [
        "data = pd.DataFrame(iris['data'], columns = iris['feature_names'] )\r\n",
        "target = pd.DataFrame(iris['target'],columns = ['target'])"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7udMh9d21yA"
      },
      "source": [
        "#combine the input predictors and target so that it can be split into training and testing\r\n",
        "data_target = data.join(target)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "4LVO_mbcCzji",
        "outputId": "c62369a8-e13b-42f3-c514-9936bd304558"
      },
      "source": [
        "data_target.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n",
              "0                5.1               3.5  ...               0.2       0\n",
              "1                4.9               3.0  ...               0.2       0\n",
              "2                4.7               3.2  ...               0.2       0\n",
              "3                4.6               3.1  ...               0.2       0\n",
              "4                5.0               3.6  ...               0.2       0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKA6-qX0DI4d",
        "outputId": "d9c4bff4-3eb5-4f17-b554-22ef513a1275"
      },
      "source": [
        "data_target['target'].value_counts()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    50\n",
              "1    50\n",
              "0    50\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdjLHzos6Dkh"
      },
      "source": [
        "#for this implementaion, let's make the problem a binary. So considering only '0' and '1' as the target\r\n",
        "X = np.array(data_target[(data_target['target'] == 0) | (data_target['target'] == 1)].drop('target', axis=1))\r\n",
        "y = np.array(data_target[(data_target['target'] == 0) | (data_target['target'] == 1)]['target']).reshape(100,1)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SpYBBWIe_8pQ",
        "outputId": "567e8789-8392-438d-93e1-d9de96900edf"
      },
      "source": [
        "train_x,test_x,train_y,test_y = train_test_split(X,y,test_size = 0.2)\r\n",
        "\r\n",
        "print('Shape of train_x:', train_x.shape)\r\n",
        "print('Shape of train_y:', train_y.shape)\r\n",
        "print('Shape of test_x:', test_x.shape)\r\n",
        "print('Shape of test_y:', test_y.shape)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train_x: (80, 4)\n",
            "Shape of train_y: (80, 1)\n",
            "Shape of test_x: (20, 4)\n",
            "Shape of test_y: (20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0jRKI3Z_-vp"
      },
      "source": [
        "# intializing the weights for each layer\r\n",
        "def intialize_weights(layer_dims):\r\n",
        "    np.random.seed(3)\r\n",
        "    parameters = {}\r\n",
        "    L = len(layer_dims)\r\n",
        "    \r\n",
        "    #initialise the value of weights based on the number of layers\r\n",
        "    for i in range(1,L):\r\n",
        "        parameters['W'+str(i)] = np.random.randn(layer_dims[i-1],layer_dims[i]) * 0.01\r\n",
        "        parameters['b'+str(i)] = np.zeros([1, layer_dims[i]])    \r\n",
        "            \r\n",
        "    return parameters"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW-QL8EXAUHk"
      },
      "source": [
        "#forward propagation\r\n",
        "def forward_propagation(layer_dims,train_x,parameters):\r\n",
        "    \r\n",
        "    caches = []\r\n",
        "    Aprev = train_x\r\n",
        "    L = len(layer_dims)\r\n",
        "    \r\n",
        "    #forward propagation for all the layers except last layer\r\n",
        "    for i in range(1,L-1): \r\n",
        "        W = parameters['W'+ str(i)]\r\n",
        "        b = parameters['b' + str(i)] \r\n",
        "        Z = np.dot(Aprev, W) + b  \r\n",
        "        Aprev = np.maximum(0,Z)        \r\n",
        "        cache = Aprev, W,b\r\n",
        "        caches.append(cache)         \r\n",
        "    \r\n",
        "    #forward propagation for the last layer\r\n",
        "    W = parameters['W'+ str(L-1)]\r\n",
        "    b = parameters['b' + str(L-1)]\r\n",
        "    Zlast = np.dot(Aprev, W) + b    \r\n",
        "    Alast = 1/(1 + np.exp(-Zlast))    \r\n",
        "    cache = Alast, W, b\r\n",
        "    caches.append(cache)\r\n",
        "    return caches"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3XNDvErBn1s"
      },
      "source": [
        "#cost function calculation\r\n",
        "def cost_calculate(predict_y,train_y):\r\n",
        "    m = train_y.shape[0]\r\n",
        "    cost = -(np.dot(train_y.T, np.log(predict_y)) + np.dot((1-train_y).T, np.log(1-predict_y)))/m\r\n",
        "    return cost"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tTBZP6jBqq9"
      },
      "source": [
        "def backward_propagation(layer_dims, caches, parameters, train_y, learning_rate):\r\n",
        "    #backward propagation for the last layer\r\n",
        "    #Extract the last array from the caches, as this corresponds to the final output\r\n",
        "    L = len(layer_dims)    \r\n",
        "    Acurr,Wcurr,bcurr = caches[L - 2]  \r\n",
        "    Aprev,Wprev,bprev = caches[L - 3]\r\n",
        "    \r\n",
        "    m = train_y.shape[0]    \r\n",
        "    \r\n",
        "    dzprev = (Acurr - train_y)    \r\n",
        "    dwlast = np.dot(Aprev.T, dzprev)/m    \r\n",
        "    dblast = np.sum(dzprev, keepdims = True, axis = 0)/m        \r\n",
        "    parameters['W' + str(L-1)]= parameters['W' + str(L-1)] - (learning_rate * dwlast)    \r\n",
        "    parameters['b' + str(L-1)]= parameters['b' + str(L-1)] - (learning_rate * dblast)    \r\n",
        "        \r\n",
        "    for i in reversed(range(L-2)):\r\n",
        "        Anext,Wnext,bnext = caches[i+1]\r\n",
        "        Acurr,Wcurr,bcurr = caches[i]  \r\n",
        "        if i == 0:\r\n",
        "            Aprev = train_x\r\n",
        "        else:            \r\n",
        "            Aprev,Wprev,bprev = caches[i-1]\r\n",
        "                \r\n",
        "        dzcurr = np.where(Acurr > 0,1,Acurr)     \r\n",
        "        dzprev = np.multiply(np.dot(dzprev,Wnext.T), dzcurr)\r\n",
        "        dW = np.dot(Aprev.T,dzprev)/m\r\n",
        "        db = np.sum(dzprev, keepdims = True, axis = 0)/m  \r\n",
        "        parameters['W' + str(i+1)]= parameters['W' + str(i+1)] - (learning_rate * dW)\r\n",
        "        parameters['b' + str(i+1)]= parameters['b' + str(i+1)] - (learning_rate * db)     \r\n",
        "        return parameters"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpils_ocBsuE"
      },
      "source": [
        "def complete_model(layer_dims, train_x, train_y, learning_rate, iterations):\r\n",
        "    \r\n",
        "    L = len(layer_dims)\r\n",
        "    # Intialize the weights\r\n",
        "    parameters = intialize_weights(layer_dims)\r\n",
        "    \r\n",
        "    for i in range(iterations):\r\n",
        "        #forward propagation\r\n",
        "        caches = forward_propagation(layer_dims,train_x,parameters)\r\n",
        "        \r\n",
        "        #calculate the cost \r\n",
        "        A,W,b = caches[-1]\r\n",
        "        cost = cost_calculate(A,train_y)\r\n",
        "        if i%1000 == 0:\r\n",
        "            print('The cost after iteration {}: {}'.format(i, np.squeeze(cost)))\r\n",
        "                  \r\n",
        "        #backward propagation\r\n",
        "        parameters = backward_propagation(layer_dims, caches, parameters, train_y, learning_rate)\r\n",
        "    return parameters\r\n",
        "\r\n",
        "        "
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhaYmXBvBvMZ",
        "outputId": "56f9ca6a-563c-4cef-e437-8117417fc839"
      },
      "source": [
        "layer_dims = [4,5,3,1]\r\n",
        "learning_rate = 0.15\r\n",
        "iterations = 14900\r\n",
        "parameters = complete_model(layer_dims, train_x, train_y, learning_rate, iterations)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The cost after iteration 0: 0.6931458662427084\n",
            "The cost after iteration 1000: 0.6928176749538959\n",
            "The cost after iteration 2000: 0.6926375234627491\n",
            "The cost after iteration 3000: 0.6905539990663362\n",
            "The cost after iteration 4000: 0.6674492997222916\n",
            "The cost after iteration 5000: 0.4943033781872236\n",
            "The cost after iteration 6000: 0.22287462328522417\n",
            "The cost after iteration 7000: 0.09010404330852087\n",
            "The cost after iteration 8000: 0.05181617021726566\n",
            "The cost after iteration 9000: 0.035345626279470674\n",
            "The cost after iteration 10000: 0.02656350008290693\n",
            "The cost after iteration 11000: 0.021191446335718244\n",
            "The cost after iteration 12000: 0.017610774821345116\n",
            "The cost after iteration 13000: 0.015068752173866001\n",
            "The cost after iteration 14000: 0.013179961770325327\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl-MKLHOpRvf"
      },
      "source": [
        "predict = forward_propagation(layer_dims,test_x,parameters)[-1][0]\r\n",
        "test_cost = cost_calculate(predict,test_y)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8TA0_mNpnL6",
        "outputId": "7db73f4c-d0b5-4a34-adbb-8549bccefa4a"
      },
      "source": [
        "test_cost"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0122371]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjR4tNVap79Q"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Dense(50, input_shape = (4, )))\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(Dense(50))\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(Dense(1))\r\n",
        "model.add(Activation('sigmoid'))\r\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrB0OgqlrNrV"
      },
      "source": [
        "sgd = optimizers.SGD(lr = 0.01)\r\n",
        "model.compile(loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_3BeNUHrU5v",
        "outputId": "a63b6b7e-567f-41dd-f6d7-5f4b92642f67"
      },
      "source": [
        "model.fit(train_x, train_y, validation_data = (test_x, test_y), epochs = 30)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "3/3 [==============================] - 2s 90ms/step - loss: 0.8223 - accuracy: 0.5016 - val_loss: 0.5828 - val_accuracy: 1.0000\n",
            "Epoch 2/30\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.5699 - accuracy: 1.0000 - val_loss: 0.5183 - val_accuracy: 1.0000\n",
            "Epoch 3/30\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.5108 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 1.0000\n",
            "Epoch 4/30\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4502 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 1.0000\n",
            "Epoch 5/30\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.4093 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 1.0000\n",
            "Epoch 6/30\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.3725 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 1.0000\n",
            "Epoch 7/30\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3329 - accuracy: 1.0000 - val_loss: 0.3197 - val_accuracy: 1.0000\n",
            "Epoch 8/30\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.3059 - accuracy: 1.0000 - val_loss: 0.2922 - val_accuracy: 1.0000\n",
            "Epoch 9/30\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2751 - accuracy: 1.0000 - val_loss: 0.2641 - val_accuracy: 1.0000\n",
            "Epoch 10/30\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2492 - accuracy: 1.0000 - val_loss: 0.2401 - val_accuracy: 1.0000\n",
            "Epoch 11/30\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.2250 - accuracy: 1.0000 - val_loss: 0.2302 - val_accuracy: 1.0000\n",
            "Epoch 12/30\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.1985 - accuracy: 1.0000 - val_loss: 0.1948 - val_accuracy: 1.0000\n",
            "Epoch 13/30\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1816 - accuracy: 1.0000 - val_loss: 0.1815 - val_accuracy: 1.0000\n",
            "Epoch 14/30\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1740 - accuracy: 1.0000 - val_loss: 0.1697 - val_accuracy: 1.0000\n",
            "Epoch 15/30\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1503 - accuracy: 1.0000 - val_loss: 0.1483 - val_accuracy: 1.0000\n",
            "Epoch 16/30\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 0.1358 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 1.0000\n",
            "Epoch 17/30\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1208 - accuracy: 1.0000 - val_loss: 0.1211 - val_accuracy: 1.0000\n",
            "Epoch 18/30\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1046 - accuracy: 1.0000 - val_loss: 0.1103 - val_accuracy: 1.0000\n",
            "Epoch 19/30\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0944 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 1.0000\n",
            "Epoch 20/30\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0821 - accuracy: 1.0000 - val_loss: 0.0856 - val_accuracy: 1.0000\n",
            "Epoch 21/30\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0768 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 1.0000\n",
            "Epoch 22/30\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0708 - accuracy: 1.0000 - val_loss: 0.0690 - val_accuracy: 1.0000\n",
            "Epoch 23/30\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0590 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.0534 - accuracy: 1.0000 - val_loss: 0.0585 - val_accuracy: 1.0000\n",
            "Epoch 25/30\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0498 - accuracy: 1.0000 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
            "Epoch 26/30\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0417 - accuracy: 1.0000 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
            "Epoch 27/30\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0386 - accuracy: 1.0000 - val_loss: 0.0411 - val_accuracy: 1.0000\n",
            "Epoch 28/30\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.0368 - val_accuracy: 1.0000\n",
            "Epoch 29/30\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
            "Epoch 30/30\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 0.0283 - accuracy: 1.0000 - val_loss: 0.0298 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f49cff0a940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJVK6wV_rk5v"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}